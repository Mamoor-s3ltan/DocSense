
# ğŸ§  DocSense â€“ AI-Powered Document Chat (RAG)

DocSense is an AI-powered document assistant that allows users to upload documents and chat with them using **Retrieval-Augmented Generation (RAG)**.

Instead of generating generic AI responses, DocSense retrieves relevant document chunks using vector embeddings and produces context-aware answers grounded in the uploaded content.

---

## ğŸš€ Features

- ğŸ“„ Document upload & processing  
- âœ‚ï¸ Intelligent text chunking  
- ğŸ§  Embedding generation  
- ğŸ“¦ Vector storage using Supabase  
- ğŸ” Semantic similarity search  
- ğŸ’¬ Conversational chat interface  
- ğŸ¦™ Local LLM inference using Ollama  
- ğŸ” Secure authentication system  
- ğŸ¨ Modern UI with Tailwind CSS & Material UI  

---

## ğŸ—ï¸ Tech Stack

### Frontend
- Next.js (App Router)
- TypeScript
- Tailwind CSS
- Material UI

### Backend / AI Layer
- LangChain (RAG pipeline)
- Ollama (Local LLM execution)

### Database & Authentication
- Supabase (Vector embeddings storage)
- Supabase Authentication

---

## ğŸ§  How It Works (RAG Architecture)

1. User uploads a document  
2. The document is split into smaller chunks  
3. Embeddings are generated for each chunk  
4. Embeddings are stored in Supabase  
5. When a user asks a question:
   - Relevant chunks are retrieved via semantic search  
   - Retrieved context is sent to the LLM (Ollama)  
   - The AI generates a grounded response  

This ensures answers are based strictly on the uploaded document.

---

## âš™ï¸ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Mamoor-s3ltan/DocSense.git
cd DocSense
```
### 2ï¸âƒ£ Install Dependencies
```bash
npm install
```
### 3ï¸âƒ£ Setup Environment Variables
```bash
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_key
```
### 4ï¸âƒ£ Run Ollama Locally
```bash
ollama run qwen2:7b
```
### 5ï¸âƒ£ Start Development Server
```bash
npm run dev
```
## ğŸ¯ Project Goals
- Build a full-stack AI SaaS application
- Implement a production-style RAG architecture
- Work with vector databases and semantic search
- Run LLMs locally for privacy and performance
- Combine modern UI with AI engineering

---

## ğŸ“¸ Screenshots

### ğŸ  Home Page
![Home Page](./screenshots/HomePage.png)

---

### Signup Page
![Auth Page](./screenshots/SignupPage.png)

### ğŸ’¬ Chat Interface
![Chat Interface](./screenshots/UploadDocs.png)

---


